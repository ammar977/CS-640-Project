{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0ca8f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb5ee5",
   "metadata": {},
   "source": [
    "# Modify Data Files\n",
    "\n",
    "Creates a new file \"images.tfrecords\" which contains all of the images that had labels in the label sheet. This will only have to be done if you haven't done it already. First unzip \"images.zip\" into the \"../Data Instagram\" directory and copy \"Labeled_instagram_posts_related_to_covid.xlsx\" into the same location. Then run rename_files() to prepare the files for the next step. Run get_labeled_images_raw() to get the matching images and their associated labels. Finally run the cells under \"Create TFRecord File\" to create the \"images.tfrecords\" file used by the rest of the notebook. If the \"images.tfrecords\" file already exists, skip all of this and go to the \"5-Fold Cross-Validation\" section.\n",
    "\n",
    "## Get Data Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50af65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_post_data = pd.read_excel(\"../Data Instagram/Labeled_instagram_posts_related_to_covid.xlsx\",\n",
    "                             usecols=\"A, N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd50613",
   "metadata": {},
   "source": [
    "## Get Instagram Image Set\n",
    "\n",
    "Find the corresponding images for the labels we just loaded. Because the file names have extra, unhelpful information at the front, first we remove that information. This allows us to search directly for the image as imagename.jpg. Run rename_files() once if you have not changed the file names already. The images are resized to fit the model inside of get_labeled_images()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3451f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files():\n",
    "    # Rename all image files in \"Data Instagram\", removing the leading integer and underscore\n",
    "    for filename in os.listdir(\"../Data Instagram\"):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            new_name = re.sub(r\"\\d*_\", \"\", filename)\n",
    "            \n",
    "            if not os.path.exists(\"../Data Instagram/\" + new_name):\n",
    "                os.rename(\"../Data Instagram/\" + filename, \"../Data Instagram/\" + new_name)\n",
    "\n",
    "rename_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0906dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_images_raw(image_data):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Get image file name and label\n",
    "    for post in image_data.itertuples():\n",
    "        _, imagename, label = post\n",
    "        \n",
    "        # Change label to binary\n",
    "        if label != 1:\n",
    "            label = 0\n",
    "        \n",
    "        # Load and resize image\n",
    "        file_name = imagename + \".jpg\"\n",
    "        image_file_path = \"../Data Instagram/Matching/\" + file_name\n",
    "        if os.path.exists(image_file_path):\n",
    "            picture = tf.io.read_file(image_file_path)\n",
    "            #picture = tf.image.decode_jpeg(picture, channels=3)\n",
    "            #picture = tf.image.resize_with_pad(picture, 480, 480)\n",
    "            images.append(picture)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f635aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_images_raw, ig_labels = get_labeled_images_raw(ig_post_data)  # Will store the images we learn with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "956dd1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ig_images_raw[0]))\n",
    "print(type(ig_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1184ea",
   "metadata": {},
   "source": [
    "## Create TFRecord File\n",
    "\n",
    "Will only need the file \"images.tfrecords\" from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c93b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(raw_image, label):\n",
    "    # Create Feature objects from image and label data\n",
    "    lbl = tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "    if isinstance(raw_image, type(tf.constant(0))):\n",
    "        raw_image = raw_image.numpy()  # Change from EagerTensor\n",
    "    image_string = tf.train.Feature(bytes_list=tf.train.BytesList(value=[raw_image]))\n",
    "    \n",
    "    # Make dictionary for example\n",
    "    features = {\"label\": lbl,\n",
    "                \"image_raw\": image_string}\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9b72aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"../Data Instagram/images.tfrecords\"\n",
    "with tf.io.TFRecordWriter(output_filename) as writer:\n",
    "    for i in range(len(ig_images_raw)):\n",
    "        ex = create_example(ig_images_raw[i], ig_labels[i])\n",
    "        writer.write(ex.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7233de2",
   "metadata": {},
   "source": [
    "# 5-Fold Cross-Validation on Instagram Images with Various Models\n",
    "\n",
    "Run the cross-validation loop once per each model. The results are stored in the Excel sheet \"Model_Results\", where the averages are calculated across the splits.\n",
    "\n",
    "## Set Up\n",
    "\n",
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "882a00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(cv_round, images, num_images):\n",
    "    vs = int(num_images / 5) # 20% for validation, 5-fold validation\n",
    "    valid_start = (cv_round) * vs\n",
    "    valid_end = (cv_round+1) * vs if cv_round != 4 else -1\n",
    "\n",
    "    # Split data\n",
    "    training_ds = images.take(valid_start).concatenate(images.skip(valid_end))\n",
    "    validation_ds = images.skip(valid_start).take(vs)\n",
    "    \n",
    "    return training_ds, validation_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "354535b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(tds, vds):\n",
    "    # Batch setup\n",
    "    batch_size = 32\n",
    "    training_ds = tds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "    validation_ds = vds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "    \n",
    "    return training_ds, validation_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163676e7",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3cafc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1():\n",
    "    \"\"\"\n",
    "    A basic model with one classifier layer built on top of ResNet50 v2.\n",
    "    The classification layer uses an average pooling layer followed by a sigmoid activation layer\n",
    "    for binary classification.\n",
    "    \"\"\"\n",
    "    # Instantiate pre-trained ResNet\n",
    "    base = keras.applications.ResNet50V2(include_top=False,\n",
    "                                     weights=\"imagenet\",\n",
    "                                     input_shape=(480, 480, 3))\n",
    "    base.trainable = False\n",
    "    \n",
    "    # Create classifier\n",
    "    inputs = keras.Input(shape=(480, 480, 3))\n",
    "    a = base(inputs, training=False)\n",
    "    a = keras.layers.GlobalAveragePooling2D()(a)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(a)\n",
    "    classifier = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile model\n",
    "    classifier.compile(optimizer=keras.optimizers.Adam(),\n",
    "                       loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                       metrics=[keras.metrics.BinaryAccuracy(),\n",
    "                                keras.metrics.Recall(),\n",
    "                                keras.metrics.Precision()])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a4909b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2():\n",
    "    \"\"\"\n",
    "    A model with one classifier layer built on top of ResNet50 v2.\n",
    "    The classification layer uses an average pooling layer followed by a sigmoid activation layer\n",
    "    for binary classification.\n",
    "    Adds a data augmentation layer to the input.\n",
    "    \"\"\"\n",
    "    # Instantiate pre-trained ResNet\n",
    "    base = keras.applications.ResNet50V2(include_top=False,\n",
    "                                     weights=\"imagenet\",\n",
    "                                     input_shape=(480, 480, 3))\n",
    "    base.trainable = False\n",
    "    \n",
    "    # Create classifier\n",
    "    inputs = keras.Input(shape=(480, 480, 3))\n",
    "    augmentation = keras.layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    augmentation = keras.layers.RandomRotation(0.1)(augmentation)\n",
    "    a = base(augmentation, training=False)\n",
    "    a = keras.layers.GlobalAveragePooling2D()(a)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(a)\n",
    "    classifier = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile model\n",
    "    classifier.compile(optimizer=keras.optimizers.Adam(),\n",
    "                       loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                       metrics=[keras.metrics.BinaryAccuracy(),\n",
    "                                keras.metrics.Recall(),\n",
    "                                keras.metrics.Precision()])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e7ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3():\n",
    "    \"\"\"\n",
    "    A model with one classifier layer built on top of ResNet50 v2.\n",
    "    The classification layer uses an average pooling layer followed by a sigmoid activation layer\n",
    "    for binary classification.\n",
    "    Adds a data augmentation layer to the input.\n",
    "    \"\"\"\n",
    "    # Instantiate pre-trained ResNet\n",
    "    base = keras.applications.ResNet50V2(include_top=False,\n",
    "                                     weights=\"imagenet\",\n",
    "                                     input_shape=(480, 480, 3))\n",
    "    base.trainable = False\n",
    "    \n",
    "    # Create classifier\n",
    "    inputs = keras.Input(shape=(480, 480, 3))\n",
    "    augmentation = keras.layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    augmentation = keras.layers.RandomRotation(0.1)(augmentation)\n",
    "    a = base(augmentation, training=False)\n",
    "    a = keras.layers.GlobalAveragePooling2D()(a)\n",
    "    a = keras.layers.Dense(2048, activation=\"relu\")(a)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(a)\n",
    "    classifier = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile model\n",
    "    classifier.compile(optimizer=keras.optimizers.Adam(),\n",
    "                       loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                       metrics=[keras.metrics.BinaryAccuracy(),\n",
    "                                keras.metrics.Recall(),\n",
    "                                keras.metrics.Precision()])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac90ca5",
   "metadata": {},
   "source": [
    "### One-time Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0be35424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.8543270711425932, 1: 5.864693446088795}\n",
      "{'image_raw': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'label': <tf.Tensor 'args_1:0' shape=() dtype=int64>}\n"
     ]
    }
   ],
   "source": [
    "def count_positive_labels(old_state, input_element):\n",
    "    lbl = input_element[\"label\"]\n",
    "    new_state = old_state + lbl\n",
    "    return new_state\n",
    "\n",
    "def process_image(ds_elem):\n",
    "    print(ds_elem)\n",
    "    image = ds_elem[\"image_raw\"]\n",
    "    label = ds_elem[\"label\"]\n",
    "    \n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize_with_pad(image, 480, 480)\n",
    "    image = keras.applications.resnet_v2.preprocess_input(image)\n",
    "    return (image, label)\n",
    "\n",
    "image_features = {\"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "                  \"image_raw\": tf.io.FixedLenFeature([], tf.string)}\n",
    "images_ds = tf.data.TFRecordDataset(\"../Data Instagram/images.tfrecords\")\n",
    "images_ds = images_ds.map(lambda x: tf.io.parse_single_example(x, image_features))\n",
    "\n",
    "# Create weight dictionary to offset imbalanced data\n",
    "num_images = images_ds.reduce(np.int64(0), lambda x, _: x + 1).numpy()\n",
    "num_pos = images_ds.reduce(np.int64(0), count_positive_labels).numpy()\n",
    "\n",
    "pos_cls_wgt = (num_images - num_pos) / num_pos\n",
    "neg_cls_wgt = (num_images - num_pos) / num_images\n",
    "\n",
    "cls_wgts_dic = {0: neg_cls_wgt, 1: pos_cls_wgt}\n",
    "print(cls_wgts_dic)\n",
    "\n",
    "# Prepare images\n",
    "images_ds = images_ds.map(process_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6c4574",
   "metadata": {},
   "source": [
    "## Cross-Validation Loop\n",
    "\n",
    "The loop records the individual splits' performances in model_results, which is a list of tf.keras.callback.History objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1a670a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8736/2107566091.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     result = model.fit(trainset,\n\u001b[0m\u001b[0;32m     14\u001b[0m                        \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                        \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls_wgts_dic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs640\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs640\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs640\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs640\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs640\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    973\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs640\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs640\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs640\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs640\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_results = []\n",
    "for i in range(0, 5):\n",
    "    # Create the ith data split\n",
    "    trainset, validset = split_data(i, images_ds, num_images)\n",
    "    \n",
    "    # Prepare data\n",
    "    trainset, validset = prepare_batch(trainset, validset)\n",
    "    \n",
    "    # Get model, change the number to get a different model\n",
    "    model = build_model2()\n",
    "    \n",
    "    # Fit model\n",
    "    result = model.fit(trainset,\n",
    "                       epochs=10,\n",
    "                       class_weight=cls_wgts_dic,\n",
    "                       validation_data=validset)\n",
    "    model_results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950d8e24",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Prints the results from model_results. Only shows the last validation metrics for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(\"Results on validation sets:\")\n",
    "for i in range(5):\n",
    "    result = model_results[i]\n",
    "    suffix = ''\n",
    "    if i != 0:\n",
    "        suffix = '_' + str(i)\n",
    "    \n",
    "    print(\"Split \" + str(i+1))\n",
    "    print(\"Accuracy: {0}\\nPrecision: {1}\\nRecall: {2}\".format(\n",
    "        result.history['val_binary_accuracy'][-1],\n",
    "        result.history['val_precision' + suffix][-1],\n",
    "        result.history['val_recall' + suffix][-1]))\n",
    "    print(\"--------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
