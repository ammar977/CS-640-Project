{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a5e2c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow==2.7.0\n",
      "  Downloading tensorflow-2.7.0-cp38-cp38-manylinux2010_x86_64.whl (489.6 MB)\n",
      "\u001b[K     |███████████████████▍            | 296.0 MB 172.9 MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (3.17.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (3.3.0)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 116.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (1.6.3)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (1.12)\n",
      "Collecting keras<2.8,>=2.7.0rc0\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 132.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.32.0 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (0.36.2)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.22.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 137.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (3.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (1.15.0)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-12.0.0-py2.py3-none-manylinux1_x86_64.whl (13.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.4 MB 138.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (1.1.2)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "\u001b[K     |████████████████████████████████| 463 kB 127.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (1.34.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (1.19.5)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorflow==2.7.0) (0.12.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.32.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /share/pkg.7/tensorflow/2.5.0/install/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.1.1)\n",
      "Installing collected packages: tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, libclang, keras, tensorflow\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/usr4/cs640g/adtitus/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/usr4/cs640g/adtitus/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-io 0.19.0 requires tensorflow<2.6.0,>=2.5.0, but you have tensorflow 2.7.0 which is incompatible.\n",
      "tensorflow-io 0.19.0 requires tensorflow-io-gcs-filesystem==0.19.0, but you have tensorflow-io-gcs-filesystem 0.22.0 which is incompatible.\u001b[0m\n",
      "Successfully installed keras-2.7.0 libclang-12.0.0 tensorboard-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.22.0\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/share/pkg.7/python3/3.8.10/install/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0ca8f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb5ee5",
   "metadata": {},
   "source": [
    "# Modify Data Files\n",
    "\n",
    "Creates a new file \"images.tfrecords\" which contains all of the images that had labels in the label sheet. This will only have to be done if you haven't done it already. First unzip \"images.zip\" into the \"../Data Instagram\" directory and copy \"Labeled_instagram_posts_related_to_covid.xlsx\" into the same location. Then run rename_files() to prepare the files for the next step. Run get_labeled_images_raw() to get the matching images and their associated labels. Finally run the cells under \"Create TFRecord File\" to create the \"images.tfrecords\" file used by the rest of the notebook. If the \"images.tfrecords\" file already exists, skip all of this and go to the \"5-Fold Cross-Validation\" section.\n",
    "\n",
    "## Get Data Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50af65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_post_data = pd.read_excel(\"../Data Instagram/Labeled_instagram_posts_related_to_covid.xlsx\",\n",
    "                             usecols=\"A, N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd50613",
   "metadata": {},
   "source": [
    "## Get Instagram Image Set\n",
    "\n",
    "Find the corresponding images for the labels we just loaded. Because the file names have extra, unhelpful information at the front, first we remove that information. This allows us to search directly for the image as imagename.jpg. Run rename_files() once if you have not changed the file names already. The images are resized to fit the model inside of get_labeled_images()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3451f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files():\n",
    "    # Rename all image files in \"Data Instagram\", removing the leading integer and underscore\n",
    "    for filename in os.listdir(\"../Data Instagram\"):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            new_name = re.sub(r\"\\d*_\", \"\", filename)\n",
    "            \n",
    "            if not os.path.exists(\"../Data Instagram/\" + new_name):\n",
    "                os.rename(\"../Data Instagram/\" + filename, \"../Data Instagram/\" + new_name)\n",
    "\n",
    "rename_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0906dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_images_raw(image_data):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Get image file name and label\n",
    "    for post in image_data.itertuples():\n",
    "        _, imagename, label = post\n",
    "        \n",
    "        # Change label to binary\n",
    "        if label != 1:\n",
    "            label = 0\n",
    "        \n",
    "        # Load and resize image\n",
    "        file_name = imagename + \".jpg\"\n",
    "        image_file_path = \"../Data Instagram/Matching/\" + file_name\n",
    "        if os.path.exists(image_file_path):\n",
    "            picture = tf.io.read_file(image_file_path)\n",
    "            #picture = tf.image.decode_jpeg(picture, channels=3)\n",
    "            #picture = tf.image.resize_with_pad(picture, 480, 480)\n",
    "            images.append(picture)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f635aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_images_raw, ig_labels = get_labeled_images_raw(ig_post_data)  # Will store the images we learn with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "956dd1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ig_images_raw[0]))\n",
    "print(type(ig_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1184ea",
   "metadata": {},
   "source": [
    "## Create TFRecord File\n",
    "\n",
    "Will only need the file \"images.tfrecords\" from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c93b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(raw_image, label):\n",
    "    # Create Feature objects from image and label data\n",
    "    lbl = tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "    if isinstance(raw_image, type(tf.constant(0))):\n",
    "        raw_image = raw_image.numpy()  # Change from EagerTensor\n",
    "    image_string = tf.train.Feature(bytes_list=tf.train.BytesList(value=[raw_image]))\n",
    "    \n",
    "    # Make dictionary for example\n",
    "    features = {\"label\": lbl,\n",
    "                \"image_raw\": image_string}\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9b72aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"../Data Instagram/images.tfrecords\"\n",
    "with tf.io.TFRecordWriter(output_filename) as writer:\n",
    "    for i in range(len(ig_images_raw)):\n",
    "        ex = create_example(ig_images_raw[i], ig_labels[i])\n",
    "        writer.write(ex.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7233de2",
   "metadata": {},
   "source": [
    "# 5-Fold Cross-Validation on Instagram Images with Various Models\n",
    "\n",
    "Run the cross-validation loop once per each model. The results are stored in the Excel sheet \"Model_Results\", where the averages are calculated across the splits.\n",
    "\n",
    "## Set Up\n",
    "\n",
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "882a00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(cv_round, images, num_images):\n",
    "    vs = int(num_images / 5) # 20% for validation, 5-fold validation\n",
    "    valid_start = (cv_round) * vs\n",
    "    valid_end = (cv_round+1) * vs if cv_round != 4 else -1\n",
    "\n",
    "    # Split data\n",
    "    training_ds = images.take(valid_start).concatenate(images.skip(valid_end))\n",
    "    validation_ds = images.skip(valid_start).take(vs)\n",
    "    \n",
    "    return training_ds, validation_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "354535b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(tds, vds):\n",
    "    # Batch setup\n",
    "    batch_size = 32\n",
    "    training_ds = tds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "    validation_ds = vds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "    \n",
    "    return training_ds, validation_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163676e7",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3cafc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1():\n",
    "    \"\"\"\n",
    "    A basic model with one classifier layer built on top of ResNet50 v2.\n",
    "    The classification layer uses an average pooling layer followed by a sigmoid activation layer\n",
    "    for binary classification.\n",
    "    \"\"\"\n",
    "    # Instantiate pre-trained ResNet\n",
    "    base = keras.applications.ResNet50V2(include_top=False,\n",
    "                                     weights=\"imagenet\",\n",
    "                                     input_shape=(480, 480, 3))\n",
    "    base.trainable = False\n",
    "    \n",
    "    # Create classifier\n",
    "    inputs = keras.Input(shape=(480, 480, 3))\n",
    "    a = base(inputs, training=False)\n",
    "    a = keras.layers.GlobalAveragePooling2D()(a)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(a)\n",
    "    classifier = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile model\n",
    "    classifier.compile(optimizer=keras.optimizers.Adam(),\n",
    "                       loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                       metrics=[keras.metrics.BinaryAccuracy(),\n",
    "                                keras.metrics.Recall(),\n",
    "                                keras.metrics.Precision()])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a4909b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2():\n",
    "    \"\"\"\n",
    "    A model with one classifier layer built on top of ResNet50 v2.\n",
    "    The classification layer uses an average pooling layer followed by a sigmoid activation layer\n",
    "    for binary classification.\n",
    "    Adds a data augmentation layer to the input.\n",
    "    \"\"\"\n",
    "    # Instantiate pre-trained ResNet\n",
    "    base = keras.applications.ResNet50V2(include_top=False,\n",
    "                                     weights=\"imagenet\",\n",
    "                                     input_shape=(480, 480, 3))\n",
    "    base.trainable = False\n",
    "    \n",
    "    # Create classifier\n",
    "    inputs = keras.Input(shape=(480, 480, 3))\n",
    "    #augmentation = keras.layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    #augmentation = keras.layers.RandomRotation(0.1)(augmentation)\n",
    "    a = base(inputs, training=False)\n",
    "    a = keras.layers.GlobalAveragePooling2D()(a)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(a)\n",
    "    classifier = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile model\n",
    "    classifier.compile(optimizer=keras.optimizers.Adam(),\n",
    "                       loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                       metrics=[keras.metrics.BinaryAccuracy(),\n",
    "                                keras.metrics.Recall(),\n",
    "                                keras.metrics.Precision()])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95e7ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3():\n",
    "    \"\"\"\n",
    "    A model with two classifier layers built on top of ResNet50 v2.\n",
    "    The classification layer uses an average pooling layer followed by a relu activation layer.\n",
    "    It uses a sigmoid layer after that for classification.\n",
    "    \"\"\"\n",
    "    # Instantiate pre-trained ResNet\n",
    "    base = keras.applications.ResNet50V2(include_top=False,\n",
    "                                     weights=\"imagenet\",\n",
    "                                     input_shape=(480, 480, 3))\n",
    "    base.trainable = False\n",
    "    \n",
    "    # Create classifier\n",
    "    inputs = keras.Input(shape=(480, 480, 3))\n",
    "    #augmentation = keras.layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    #augmentation = keras.layers.RandomRotation(0.1)(augmentation)\n",
    "    a = base(inputs, training=False)\n",
    "    a = keras.layers.GlobalAveragePooling2D()(a)\n",
    "    a = keras.layers.Dense(2048, activation=\"relu\")(a)\n",
    "    a = keras.layers.Dense(2048, activation=\"relu\")(a)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(a)\n",
    "    classifier = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile model\n",
    "    classifier.compile(optimizer=keras.optimizers.Adam(),\n",
    "                       loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                       metrics=[keras.metrics.BinaryAccuracy(),\n",
    "                                keras.metrics.Recall(),\n",
    "                                keras.metrics.Precision()])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac90ca5",
   "metadata": {},
   "source": [
    "### One-time Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0be35424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 5.864693446088795}\n"
     ]
    }
   ],
   "source": [
    "def count_positive_labels(old_state, input_element):\n",
    "    lbl = input_element[\"label\"]\n",
    "    new_state = old_state + lbl\n",
    "    return new_state\n",
    "\n",
    "def process_image(ds_elem):\n",
    "    image = ds_elem[\"image_raw\"]\n",
    "    label = ds_elem[\"label\"]\n",
    "    \n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize_with_pad(image, 480, 480)\n",
    "    image = keras.applications.resnet_v2.preprocess_input(image)\n",
    "    return (image, label)\n",
    "\n",
    "image_features = {\"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "                  \"image_raw\": tf.io.FixedLenFeature([], tf.string)}\n",
    "images_ds = tf.data.TFRecordDataset(\"../Data Instagram/images.tfrecords\")\n",
    "images_ds = images_ds.map(lambda x: tf.io.parse_single_example(x, image_features))\n",
    "\n",
    "# Create weight dictionary to offset imbalanced data\n",
    "num_images = images_ds.reduce(np.int64(0), lambda x, _: x + 1).numpy()\n",
    "num_pos = images_ds.reduce(np.int64(0), count_positive_labels).numpy()\n",
    "\n",
    "pos_cls_wgt = (num_images - num_pos) / num_pos\n",
    "neg_cls_wgt = 1 #(num_images - num_pos) / num_images\n",
    "\n",
    "cls_wgts_dic = {0: neg_cls_wgt, 1: pos_cls_wgt}\n",
    "print(cls_wgts_dic)\n",
    "\n",
    "# Prepare images\n",
    "images_ds = images_ds.map(process_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6c4574",
   "metadata": {},
   "source": [
    "## Cross-Validation Loop\n",
    "\n",
    "The loop records the individual splits' performances in model_results, which is a list of tf.keras.callback.History objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a670a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "82/82 [==============================] - 18s 173ms/step - loss: 1.0441 - binary_accuracy: 0.7421 - recall_20: 0.7630 - precision_20: 0.3360 - val_loss: 0.3309 - val_binary_accuracy: 0.8582 - val_recall_20: 0.8090 - val_precision_20: 0.4898\n",
      "Epoch 2/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.7066 - binary_accuracy: 0.8048 - recall_20: 0.8672 - precision_20: 0.4221 - val_loss: 0.2644 - val_binary_accuracy: 0.8752 - val_recall_20: 0.6292 - val_precision_20: 0.5385\n",
      "Epoch 3/15\n",
      "82/82 [==============================] - 13s 159ms/step - loss: 0.5643 - binary_accuracy: 0.8299 - recall_20: 0.8906 - precision_20: 0.4609 - val_loss: 0.2801 - val_binary_accuracy: 0.8659 - val_recall_20: 0.7528 - val_precision_20: 0.5076\n",
      "Epoch 4/15\n",
      "82/82 [==============================] - 14s 165ms/step - loss: 0.4971 - binary_accuracy: 0.8426 - recall_20: 0.9115 - precision_20: 0.4828 - val_loss: 0.3056 - val_binary_accuracy: 0.8783 - val_recall_20: 0.6629 - val_precision_20: 0.5463\n",
      "Epoch 5/15\n",
      "82/82 [==============================] - 13s 162ms/step - loss: 0.4970 - binary_accuracy: 0.8568 - recall_20: 0.9193 - precision_20: 0.5086 - val_loss: 0.3360 - val_binary_accuracy: 0.8598 - val_recall_20: 0.7978 - val_precision_20: 0.4931\n",
      "Epoch 6/15\n",
      "82/82 [==============================] - 13s 163ms/step - loss: 0.5379 - binary_accuracy: 0.8403 - recall_20: 0.9401 - precision_20: 0.4794 - val_loss: 0.2677 - val_binary_accuracy: 0.8875 - val_recall_20: 0.3933 - val_precision_20: 0.6481\n",
      "Epoch 7/15\n",
      "82/82 [==============================] - 13s 161ms/step - loss: 0.5517 - binary_accuracy: 0.8183 - recall_20: 0.9141 - precision_20: 0.4443 - val_loss: 0.2785 - val_binary_accuracy: 0.8737 - val_recall_20: 0.5955 - val_precision_20: 0.5354\n",
      "Epoch 8/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.4689 - binary_accuracy: 0.8441 - recall_20: 0.9349 - precision_20: 0.4858 - val_loss: 0.2994 - val_binary_accuracy: 0.8459 - val_recall_20: 0.7416 - val_precision_20: 0.4615\n",
      "Epoch 9/15\n",
      "82/82 [==============================] - 13s 163ms/step - loss: 0.5679 - binary_accuracy: 0.8191 - recall_20: 0.9167 - precision_20: 0.4456 - val_loss: 0.4448 - val_binary_accuracy: 0.7288 - val_recall_20: 0.9101 - val_precision_20: 0.3253\n",
      "Epoch 10/15\n",
      "82/82 [==============================] - 13s 162ms/step - loss: 0.3752 - binary_accuracy: 0.8834 - recall_20: 0.9557 - precision_20: 0.5620 - val_loss: 0.3627 - val_binary_accuracy: 0.8721 - val_recall_20: 0.5506 - val_precision_20: 0.5326\n",
      "Epoch 11/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.3043 - binary_accuracy: 0.9099 - recall_20: 0.9688 - precision_20: 0.6263 - val_loss: 0.3479 - val_binary_accuracy: 0.8475 - val_recall_20: 0.6629 - val_precision_20: 0.4609\n",
      "Epoch 12/15\n",
      "82/82 [==============================] - 13s 159ms/step - loss: 0.2866 - binary_accuracy: 0.9088 - recall_20: 0.9583 - precision_20: 0.6248 - val_loss: 0.5835 - val_binary_accuracy: 0.7612 - val_recall_20: 0.8764 - val_precision_20: 0.3514\n",
      "Epoch 13/15\n",
      "82/82 [==============================] - 13s 164ms/step - loss: 0.2344 - binary_accuracy: 0.9265 - recall_20: 0.9714 - precision_20: 0.6745 - val_loss: 0.7478 - val_binary_accuracy: 0.7288 - val_recall_20: 0.8989 - val_precision_20: 0.3239\n",
      "Epoch 14/15\n",
      "82/82 [==============================] - 13s 159ms/step - loss: 0.1897 - binary_accuracy: 0.9369 - recall_20: 0.9896 - precision_20: 0.7037 - val_loss: 0.5949 - val_binary_accuracy: 0.8721 - val_recall_20: 0.6067 - val_precision_20: 0.5294\n",
      "Epoch 15/15\n",
      "82/82 [==============================] - 13s 156ms/step - loss: 0.1111 - binary_accuracy: 0.9650 - recall_20: 0.9948 - precision_20: 0.8110 - val_loss: 0.6593 - val_binary_accuracy: 0.8413 - val_recall_20: 0.7191 - val_precision_20: 0.4507\n",
      "Epoch 1/15\n",
      "82/82 [==============================] - 17s 172ms/step - loss: 1.0908 - binary_accuracy: 0.7452 - recall_21: 0.7918 - precision_21: 0.3465 - val_loss: 0.3392 - val_binary_accuracy: 0.8521 - val_recall_21: 0.7262 - val_precision_21: 0.4552\n",
      "Epoch 2/15\n",
      "82/82 [==============================] - 13s 158ms/step - loss: 0.6737 - binary_accuracy: 0.8118 - recall_21: 0.8638 - precision_21: 0.4352 - val_loss: 0.3096 - val_binary_accuracy: 0.8613 - val_recall_21: 0.6905 - val_precision_21: 0.4754\n",
      "Epoch 3/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.5515 - binary_accuracy: 0.8360 - recall_21: 0.9075 - precision_21: 0.4751 - val_loss: 0.3061 - val_binary_accuracy: 0.8659 - val_recall_21: 0.6667 - val_precision_21: 0.4870\n",
      "Epoch 4/15\n",
      "82/82 [==============================] - 13s 161ms/step - loss: 0.5169 - binary_accuracy: 0.8383 - recall_21: 0.9254 - precision_21: 0.4794 - val_loss: 0.3240 - val_binary_accuracy: 0.8906 - val_recall_21: 0.6429 - val_precision_21: 0.5684\n",
      "Epoch 5/15\n",
      "82/82 [==============================] - 13s 159ms/step - loss: 0.6054 - binary_accuracy: 0.8168 - recall_21: 0.9177 - precision_21: 0.4457 - val_loss: 0.2890 - val_binary_accuracy: 0.8891 - val_recall_21: 0.4286 - val_precision_21: 0.6000\n",
      "Epoch 6/15\n",
      "82/82 [==============================] - 13s 162ms/step - loss: 0.4995 - binary_accuracy: 0.8353 - recall_21: 0.9229 - precision_21: 0.4742 - val_loss: 0.3171 - val_binary_accuracy: 0.8675 - val_recall_21: 0.7619 - val_precision_21: 0.4923\n",
      "Epoch 7/15\n",
      "82/82 [==============================] - 14s 170ms/step - loss: 0.5267 - binary_accuracy: 0.8279 - recall_21: 0.9306 - precision_21: 0.4629 - val_loss: 0.4283 - val_binary_accuracy: 0.7227 - val_recall_21: 0.9048 - val_precision_21: 0.3065\n",
      "Epoch 8/15\n",
      "82/82 [==============================] - 13s 159ms/step - loss: 0.4280 - binary_accuracy: 0.8614 - recall_21: 0.9434 - precision_21: 0.5206 - val_loss: 0.5835 - val_binary_accuracy: 0.6071 - val_recall_21: 0.9762 - val_precision_21: 0.2448\n",
      "Epoch 9/15\n",
      "82/82 [==============================] - 13s 163ms/step - loss: 0.4229 - binary_accuracy: 0.8668 - recall_21: 0.9486 - precision_21: 0.5309 - val_loss: 0.5259 - val_binary_accuracy: 0.7119 - val_recall_21: 0.9167 - val_precision_21: 0.2996\n",
      "Epoch 10/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.2932 - binary_accuracy: 0.9065 - recall_21: 0.9743 - precision_21: 0.6193 - val_loss: 0.5568 - val_binary_accuracy: 0.7596 - val_recall_21: 0.8571 - val_precision_21: 0.3333\n",
      "Epoch 11/15\n",
      "82/82 [==============================] - 13s 159ms/step - loss: 0.2226 - binary_accuracy: 0.9299 - recall_21: 0.9820 - precision_21: 0.6858 - val_loss: 0.6113 - val_binary_accuracy: 0.7735 - val_recall_21: 0.8333 - val_precision_21: 0.3448\n",
      "Epoch 12/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.1739 - binary_accuracy: 0.9469 - recall_21: 0.9769 - precision_21: 0.7466 - val_loss: 0.6732 - val_binary_accuracy: 0.8629 - val_recall_21: 0.6667 - val_precision_21: 0.4786\n",
      "Epoch 13/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.1907 - binary_accuracy: 0.9465 - recall_21: 0.9769 - precision_21: 0.7451 - val_loss: 0.5460 - val_binary_accuracy: 0.8536 - val_recall_21: 0.7262 - val_precision_21: 0.4586\n",
      "Epoch 14/15\n",
      "82/82 [==============================] - 14s 165ms/step - loss: 0.0983 - binary_accuracy: 0.9734 - recall_21: 0.9949 - precision_21: 0.8524 - val_loss: 0.7234 - val_binary_accuracy: 0.8998 - val_recall_21: 0.4405 - val_precision_21: 0.6727\n",
      "Epoch 15/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.1020 - binary_accuracy: 0.9761 - recall_21: 0.9897 - precision_21: 0.8691 - val_loss: 0.7266 - val_binary_accuracy: 0.8891 - val_recall_21: 0.5714 - val_precision_21: 0.5714\n",
      "Epoch 1/15\n",
      "82/82 [==============================] - 17s 175ms/step - loss: 1.2149 - binary_accuracy: 0.7175 - recall_22: 0.7342 - precision_22: 0.3059 - val_loss: 0.3329 - val_binary_accuracy: 0.8428 - val_recall_22: 0.6667 - val_precision_22: 0.4662\n",
      "Epoch 2/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.6695 - binary_accuracy: 0.8041 - recall_22: 0.8605 - precision_22: 0.4176 - val_loss: 0.3507 - val_binary_accuracy: 0.8413 - val_recall_22: 0.7312 - val_precision_22: 0.4658\n",
      "Epoch 3/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.5351 - binary_accuracy: 0.8445 - recall_22: 0.9053 - precision_22: 0.4831 - val_loss: 0.4136 - val_binary_accuracy: 0.8644 - val_recall_22: 0.4839 - val_precision_22: 0.5294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "82/82 [==============================] - 13s 159ms/step - loss: 0.5117 - binary_accuracy: 0.8480 - recall_22: 0.9053 - precision_22: 0.4893 - val_loss: 0.4193 - val_binary_accuracy: 0.8012 - val_recall_22: 0.7849 - val_precision_22: 0.4011\n",
      "Epoch 5/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.4702 - binary_accuracy: 0.8680 - recall_22: 0.9368 - precision_22: 0.5274 - val_loss: 0.4504 - val_binary_accuracy: 0.8243 - val_recall_22: 0.7204 - val_precision_22: 0.4323\n",
      "Epoch 6/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.4150 - binary_accuracy: 0.8826 - recall_22: 0.9447 - precision_22: 0.5583 - val_loss: 0.4910 - val_binary_accuracy: 0.8490 - val_recall_22: 0.5806 - val_precision_22: 0.4779\n",
      "Epoch 7/15\n",
      "82/82 [==============================] - 14s 172ms/step - loss: 0.3237 - binary_accuracy: 0.9072 - recall_22: 0.9605 - precision_22: 0.6176 - val_loss: 0.5251 - val_binary_accuracy: 0.8721 - val_recall_22: 0.3871 - val_precision_22: 0.5806\n",
      "Epoch 8/15\n",
      "82/82 [==============================] - 13s 159ms/step - loss: 0.3069 - binary_accuracy: 0.9122 - recall_22: 0.9632 - precision_22: 0.6310 - val_loss: 1.0137 - val_binary_accuracy: 0.8644 - val_recall_22: 0.1505 - val_precision_22: 0.6087\n",
      "Epoch 9/15\n",
      "82/82 [==============================] - 13s 163ms/step - loss: 0.2909 - binary_accuracy: 0.9169 - recall_22: 0.9711 - precision_22: 0.6429 - val_loss: 0.8198 - val_binary_accuracy: 0.8629 - val_recall_22: 0.1613 - val_precision_22: 0.5769\n",
      "Epoch 10/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.2555 - binary_accuracy: 0.9273 - recall_22: 0.9658 - precision_22: 0.6759 - val_loss: 0.6814 - val_binary_accuracy: 0.8767 - val_recall_22: 0.3226 - val_precision_22: 0.6383\n",
      "Epoch 11/15\n",
      "82/82 [==============================] - 14s 169ms/step - loss: 0.1929 - binary_accuracy: 0.9484 - recall_22: 0.9842 - precision_22: 0.7450 - val_loss: 0.7675 - val_binary_accuracy: 0.8721 - val_recall_22: 0.2903 - val_precision_22: 0.6136\n",
      "Epoch 12/15\n",
      "82/82 [==============================] - 13s 163ms/step - loss: 0.3151 - binary_accuracy: 0.9080 - recall_22: 0.9500 - precision_22: 0.6213 - val_loss: 0.7947 - val_binary_accuracy: 0.8675 - val_recall_22: 0.2366 - val_precision_22: 0.5946\n",
      "Epoch 13/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.2989 - binary_accuracy: 0.9153 - recall_22: 0.9553 - precision_22: 0.6413 - val_loss: 0.9481 - val_binary_accuracy: 0.8675 - val_recall_22: 0.1828 - val_precision_22: 0.6296\n",
      "Epoch 14/15\n",
      "82/82 [==============================] - 13s 161ms/step - loss: 0.2730 - binary_accuracy: 0.9196 - recall_22: 0.9684 - precision_22: 0.6513 - val_loss: 0.4593 - val_binary_accuracy: 0.8737 - val_recall_22: 0.5914 - val_precision_22: 0.5556\n",
      "Epoch 15/15\n",
      "82/82 [==============================] - 13s 162ms/step - loss: 0.2953 - binary_accuracy: 0.9142 - recall_22: 0.9711 - precision_22: 0.6351 - val_loss: 0.6536 - val_binary_accuracy: 0.8197 - val_recall_22: 0.7849 - val_precision_22: 0.4294\n",
      "Epoch 1/15\n",
      "82/82 [==============================] - 17s 176ms/step - loss: 1.0312 - binary_accuracy: 0.7290 - recall_23: 0.7752 - precision_23: 0.3272 - val_loss: 0.4219 - val_binary_accuracy: 0.7920 - val_recall_23: 0.8372 - val_precision_23: 0.3731\n",
      "Epoch 2/15\n",
      "82/82 [==============================] - 13s 162ms/step - loss: 0.6586 - binary_accuracy: 0.7987 - recall_23: 0.8734 - precision_23: 0.4163 - val_loss: 0.3050 - val_binary_accuracy: 0.8706 - val_recall_23: 0.6977 - val_precision_23: 0.5085\n",
      "Epoch 3/15\n",
      "82/82 [==============================] - 13s 160ms/step - loss: 0.5638 - binary_accuracy: 0.8322 - recall_23: 0.9044 - precision_23: 0.4673 - val_loss: 0.3314 - val_binary_accuracy: 0.8567 - val_recall_23: 0.6744 - val_precision_23: 0.4715\n",
      "Epoch 4/15\n",
      "82/82 [==============================] - 13s 162ms/step - loss: 0.5060 - binary_accuracy: 0.8560 - recall_23: 0.9173 - precision_23: 0.5093 - val_loss: 0.4455 - val_binary_accuracy: 0.7889 - val_recall_23: 0.8488 - val_precision_23: 0.3706\n",
      "Epoch 5/15\n",
      "82/82 [==============================] - 13s 158ms/step - loss: 0.4869 - binary_accuracy: 0.8645 - recall_23: 0.9328 - precision_23: 0.5255 - val_loss: 0.3041 - val_binary_accuracy: 0.8798 - val_recall_23: 0.6279 - val_precision_23: 0.5400\n",
      "Epoch 6/15\n",
      "82/82 [==============================] - 14s 170ms/step - loss: 0.3970 - binary_accuracy: 0.8780 - recall_23: 0.9483 - precision_23: 0.5527 - val_loss: 0.5032 - val_binary_accuracy: 0.8814 - val_recall_23: 0.1977 - val_precision_23: 0.6800\n",
      "Epoch 7/15\n",
      "82/82 [==============================] - 13s 159ms/step - loss: 0.3705 - binary_accuracy: 0.8911 - recall_23: 0.9354 - precision_23: 0.5839 - val_loss: 0.3925 - val_binary_accuracy: 0.9014 - val_recall_23: 0.4302 - val_precision_23: 0.7115\n",
      "Epoch 8/15\n",
      "82/82 [==============================] - 13s 161ms/step - loss: 0.3403 - binary_accuracy: 0.8995 - recall_23: 0.9483 - precision_23: 0.6036 - val_loss: 0.4290 - val_binary_accuracy: 0.8891 - val_recall_23: 0.4186 - val_precision_23: 0.6207\n",
      "Epoch 9/15\n",
      "82/82 [==============================] - 13s 161ms/step - loss: 0.2791 - binary_accuracy: 0.9249 - recall_23: 0.9612 - precision_23: 0.6739 - val_loss: 0.4550 - val_binary_accuracy: 0.8459 - val_recall_23: 0.7558 - val_precision_23: 0.4514\n",
      "Epoch 10/15\n",
      "82/82 [==============================] - 13s 162ms/step - loss: 0.4366 - binary_accuracy: 0.8661 - recall_23: 0.9147 - precision_23: 0.5291 - val_loss: 0.5050 - val_binary_accuracy: 0.8798 - val_recall_23: 0.5814 - val_precision_23: 0.5435\n",
      "Epoch 11/15\n",
      "82/82 [==============================] - 15s 184ms/step - loss: 0.2286 - binary_accuracy: 0.9299 - recall_23: 0.9638 - precision_23: 0.6895 - val_loss: 0.5211 - val_binary_accuracy: 0.8613 - val_recall_23: 0.6744 - val_precision_23: 0.4833\n",
      "Epoch 12/15\n",
      "82/82 [==============================] - 13s 161ms/step - loss: 0.2465 - binary_accuracy: 0.9261 - recall_23: 0.9690 - precision_23: 0.6757 - val_loss: 0.4348 - val_binary_accuracy: 0.8875 - val_recall_23: 0.6163 - val_precision_23: 0.5699\n",
      "Epoch 13/15\n",
      "82/82 [==============================] - 13s 161ms/step - loss: 0.2264 - binary_accuracy: 0.9346 - recall_23: 0.9638 - precision_23: 0.7051 - val_loss: 0.5499 - val_binary_accuracy: 0.8829 - val_recall_23: 0.3140 - val_precision_23: 0.6136\n",
      "Epoch 14/15\n",
      "82/82 [==============================] - 13s 159ms/step - loss: 0.1879 - binary_accuracy: 0.9419 - recall_23: 0.9742 - precision_23: 0.7278 - val_loss: 0.6115 - val_binary_accuracy: 0.8983 - val_recall_23: 0.4535 - val_precision_23: 0.6724\n",
      "Epoch 15/15\n",
      "82/82 [==============================] - 13s 161ms/step - loss: 0.1914 - binary_accuracy: 0.9434 - recall_23: 0.9742 - precision_23: 0.7335 - val_loss: 0.6921 - val_binary_accuracy: 0.8952 - val_recall_23: 0.4302 - val_precision_23: 0.6607\n",
      "Epoch 1/15\n",
      "82/82 [==============================] - 17s 178ms/step - loss: 1.0000 - binary_accuracy: 0.7565 - recall_24: 0.7699 - precision_24: 0.3297 - val_loss: 0.4236 - val_binary_accuracy: 0.7997 - val_recall_24: 0.7521 - val_precision_24: 0.4764\n",
      "Epoch 2/15\n",
      "82/82 [==============================] - 13s 163ms/step - loss: 0.6567 - binary_accuracy: 0.8086 - recall_24: 0.8409 - precision_24: 0.4016 - val_loss: 0.4346 - val_binary_accuracy: 0.7858 - val_recall_24: 0.7769 - val_precision_24: 0.4563\n",
      "Epoch 3/15\n",
      "82/82 [==============================] - 13s 161ms/step - loss: 0.5235 - binary_accuracy: 0.8432 - recall_24: 0.9091 - precision_24: 0.4604 - val_loss: 0.6464 - val_binary_accuracy: 0.8459 - val_recall_24: 0.5041 - val_precision_24: 0.6040\n",
      "Epoch 4/15\n",
      "82/82 [==============================] - 13s 158ms/step - loss: 0.4414 - binary_accuracy: 0.8706 - recall_24: 0.9261 - precision_24: 0.5126 - val_loss: 0.7823 - val_binary_accuracy: 0.8536 - val_recall_24: 0.4380 - val_precision_24: 0.6625\n",
      "Epoch 5/15\n",
      "82/82 [==============================] - 13s 163ms/step - loss: 0.4935 - binary_accuracy: 0.8563 - recall_24: 0.9148 - precision_24: 0.4842 - val_loss: 0.4514 - val_binary_accuracy: 0.8475 - val_recall_24: 0.5207 - val_precision_24: 0.6058\n",
      "Epoch 6/15\n",
      "82/82 [==============================] - 14s 167ms/step - loss: 0.4601 - binary_accuracy: 0.8659 - recall_24: 0.8949 - precision_24: 0.5032 - val_loss: 0.5744 - val_binary_accuracy: 0.8228 - val_recall_24: 0.6446 - val_precision_24: 0.5200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "82/82 [==============================] - 13s 157ms/step - loss: 0.4262 - binary_accuracy: 0.8740 - recall_24: 0.9261 - precision_24: 0.5199 - val_loss: 0.5477 - val_binary_accuracy: 0.8120 - val_recall_24: 0.6612 - val_precision_24: 0.4969\n",
      "Epoch 8/15\n",
      "82/82 [==============================] - 13s 162ms/step - loss: 0.3782 - binary_accuracy: 0.8779 - recall_24: 0.9489 - precision_24: 0.5276 - val_loss: 0.5349 - val_binary_accuracy: 0.8305 - val_recall_24: 0.6612 - val_precision_24: 0.5369\n",
      "Epoch 9/15\n",
      "82/82 [==============================] - 13s 163ms/step - loss: 0.2881 - binary_accuracy: 0.9060 - recall_24: 0.9631 - precision_24: 0.5947 - val_loss: 0.6084 - val_binary_accuracy: 0.8475 - val_recall_24: 0.5620 - val_precision_24: 0.5965\n",
      "Epoch 10/15\n",
      "82/82 [==============================] - 13s 157ms/step - loss: 0.2624 - binary_accuracy: 0.9214 - recall_24: 0.9716 - precision_24: 0.6381 - val_loss: 0.9326 - val_binary_accuracy: 0.7904 - val_recall_24: 0.7107 - val_precision_24: 0.4599\n",
      "Epoch 11/15\n",
      "82/82 [==============================] - 13s 162ms/step - loss: 0.1943 - binary_accuracy: 0.9376 - recall_24: 0.9631 - precision_24: 0.6947 - val_loss: 1.2765 - val_binary_accuracy: 0.7488 - val_recall_24: 0.7934 - val_precision_24: 0.4103\n",
      "Epoch 12/15\n",
      "82/82 [==============================] - 13s 163ms/step - loss: 0.1943 - binary_accuracy: 0.9388 - recall_24: 0.9716 - precision_24: 0.6965 - val_loss: 1.2911 - val_binary_accuracy: 0.7797 - val_recall_24: 0.7934 - val_precision_24: 0.4486\n",
      "Epoch 13/15\n",
      "82/82 [==============================] - 13s 158ms/step - loss: 0.1773 - binary_accuracy: 0.9542 - recall_24: 0.9773 - precision_24: 0.7560 - val_loss: 0.9120 - val_binary_accuracy: 0.8228 - val_recall_24: 0.7273 - val_precision_24: 0.5176\n",
      "Epoch 14/15\n",
      "82/82 [==============================] - 13s 161ms/step - loss: 0.1610 - binary_accuracy: 0.9507 - recall_24: 0.9801 - precision_24: 0.7403 - val_loss: 1.0412 - val_binary_accuracy: 0.8475 - val_recall_24: 0.3884 - val_precision_24: 0.6528\n",
      "Epoch 15/15\n",
      "82/82 [==============================] - 13s 163ms/step - loss: 0.1451 - binary_accuracy: 0.9584 - recall_24: 0.9716 - precision_24: 0.7773 - val_loss: 0.6843 - val_binary_accuracy: 0.8166 - val_recall_24: 0.6777 - val_precision_24: 0.5062\n"
     ]
    }
   ],
   "source": [
    "model_results = []\n",
    "for i in range(0, 5):\n",
    "    # Create the ith data split\n",
    "    trainset, validset = split_data(i, images_ds, num_images)\n",
    "    \n",
    "    # Prepare data\n",
    "    trainset, validset = prepare_batch(trainset, validset)\n",
    "    \n",
    "    # Get model, change the number to get a different model\n",
    "    model = build_model3()\n",
    "    \n",
    "    # Fit model\n",
    "    result = model.fit(trainset,\n",
    "                       epochs=15,\n",
    "                       class_weight=cls_wgts_dic,\n",
    "                       validation_data=validset)\n",
    "    model_results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950d8e24",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Prints the results from model_results. Only shows the last validation metrics for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "465a9509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on validation sets:\n",
      "Split 1\n",
      "Accuracy: 0.8412942886352539\n",
      "Precision: 0.4507042169570923\n",
      "Recall: 0.7191011309623718\n",
      "--------------------\n",
      "Split 2\n",
      "Accuracy: 0.8890600800514221\n",
      "Precision: 0.5714285969734192\n",
      "Recall: 0.5714285969734192\n",
      "--------------------\n",
      "Split 3\n",
      "Accuracy: 0.8197226524353027\n",
      "Precision: 0.42941176891326904\n",
      "Recall: 0.7849462628364563\n",
      "--------------------\n",
      "Split 4\n",
      "Accuracy: 0.8952234387397766\n",
      "Precision: 0.6607142686843872\n",
      "Recall: 0.43023255467414856\n",
      "--------------------\n",
      "Split 5\n",
      "Accuracy: 0.8166409730911255\n",
      "Precision: 0.5061728358268738\n",
      "Recall: 0.6776859760284424\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(\"Results on validation sets:\")\n",
    "for i in range(5):\n",
    "    result = model_results[i]\n",
    "    suffix = '_' + str(i+20)\n",
    "    \n",
    "    print(\"Split \" + str(i+1))\n",
    "    print(\"Accuracy: {0}\\nPrecision: {1}\\nRecall: {2}\".format(\n",
    "        result.history['val_binary_accuracy'][-1],\n",
    "        result.history['val_precision' + suffix][-1],\n",
    "        result.history['val_recall' + suffix][-1]))\n",
    "    print(\"--------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
