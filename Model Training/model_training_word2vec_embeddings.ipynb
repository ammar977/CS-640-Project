{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b215d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import preprocessor \n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "from spacy.lang.en import stop_words as spacy_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef1b81",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb909e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../Data Twitter/Train/\"\n",
    "dfs = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('txt'):\n",
    "        path = os.path.join(folder_path,filename)\n",
    "        df = pd.read_csv(path,sep='\\t',header=None)\n",
    "        df = df.drop(columns=[df.columns[0],df.columns[3]])\n",
    "        dfs.append(df)\n",
    "\n",
    "df_train = pd.concat(dfs)\n",
    "df_train.columns = ['text','label']\n",
    "df_train['label_numeric'] = df_train['label'].astype('category').cat.codes\n",
    "print('total train samples : ',len(df_train))\n",
    "print(df_train['label'].value_counts())\n",
    "\n",
    "class_mapping = list(df_train['label'].astype('category').cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../Data Twitter/Dev/\"\n",
    "dfs = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('txt'):\n",
    "        path = os.path.join(folder_path,filename)\n",
    "        df = pd.read_csv(path,sep='\\t',header=None)\n",
    "        df = df.drop(columns=[df.columns[0],df.columns[3]])\n",
    "        dfs.append(df)\n",
    "\n",
    "df_dev = pd.concat(dfs)\n",
    "df_dev.columns = ['text','label']\n",
    "df_dev['label_numeric'] = df_dev['label'].astype('category').cat.codes\n",
    "print('total train samples : ',len(df_dev))\n",
    "print(df_dev['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab864b92",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe292941",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.set_options(preprocessor.OPT.URL, preprocessor.OPT.MENTION)  # removes mentions and URLs only\n",
    "stop_words = spacy_stopwords.STOP_WORDS\n",
    "punctuations = string.punctuation\n",
    "\n",
    "def preprocess(text):\n",
    "    text = preprocessor.clean(text)\n",
    "    text = re.sub(r'\\W+', ' ', text)  # remove non-alphanumeric characters\n",
    "    # replace numbers with the word 'number'\n",
    "    text = re.sub(r\"\\d+\", \"number\", text)\n",
    "    text = text.lower()  # lower case everything\n",
    "    \n",
    "    return text.strip() # remove redundant spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd609c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train['text'].apply(preprocess)\n",
    "df_dev['text'] = df_dev['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74cd62d",
   "metadata": {},
   "source": [
    "# Prepare Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8893d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gensim = api.load('glove-twitter-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ccb161",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 100\n",
    "X_train = np.zeros((len(df_train),num_features))\n",
    "for i,text in enumerate(df_train['text']):\n",
    "    count = 0\n",
    "    for word in text.split(' '):\n",
    "        try:\n",
    "            X_train[i] += model_gensim[word]\n",
    "            count+=1\n",
    "        except:\n",
    "            continue\n",
    "    X_train[i] /= count\n",
    "    \n",
    "X_test = np.zeros((len(df_dev),num_features))\n",
    "for i,text in enumerate(df_dev['text']):\n",
    "    count = 0\n",
    "    for word in text.split(' '):\n",
    "        try:\n",
    "            X_test[i] += model_gensim[word]\n",
    "            count+=1\n",
    "        except:\n",
    "            continue\n",
    "    X_test[i] /= count\n",
    "    \n",
    "Y_train = df_train['label_numeric']\n",
    "Y_test = df_dev['label_numeric']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a62fc",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ff001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "408cebb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ammarahmad/opt/anaconda3/envs/ai_project/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35973c65",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11fce517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.54      0.54      0.54        84\n",
      "        fear       0.59      0.62      0.60       110\n",
      "         joy       0.54      0.61      0.57        79\n",
      "     sadness       0.51      0.41      0.45        74\n",
      "\n",
      "    accuracy                           0.55       347\n",
      "   macro avg       0.54      0.54      0.54       347\n",
      "weighted avg       0.55      0.55      0.55       347\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred,target_names=class_mapping))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
